## Assumptions
I went about this how I would if I was asked to start this in real life, start simple - prioritize explainability over complexity. I also used python because I recalled that the job posting specified python and PYMC.

## How could your work be improved?
Using `ggplot`... Kidding, but data visualization is critical to communicating effectively. With more time, I'd refine the charts for various audiences. For instance, clearly annotating visualizations and highlighting key points – like a specific player's data in the forest plot – would significantly improve their clarity. My aim would be to create a comprehensive deliverable: an Executive Summary for leadership, detailed technical information for the Football Research & Technology team, and a general presentation for the broader organization. The best way to make an impact is to bring everyone along with the project, and tailored visualizations and tables are key to that.

That brings up another point in how this could be improved, which is feedback from stakeholders. It's critical to understand who is using it? How is this getting used? What information do we have currently and what areas are indentified as missing. All of which would provide guidence on what design direction some of this should take. The kick distribution within the model is linear values from 25-60, this is an are where feedback from leadership on what type of kicks do we want to model kickers. Do we want to look at a standard season distribution, or would we want to look at aggressive kicking seasons assuming we utilize the kicker in more difficult situations.

Within the scope of the data, I didn't incorporate anything related to age or look into weighing newer seasons for a player differently. For age, this dataset in particular has Adam Vinitari who exceled into his 40's. I did some basic analysis to look into it, and without accounting for survivorship bias (where only high-performing kickers remain in the league into older age), a naive model might attribute positive effects to increasing age. Additionally, a time series component could be included to downweight past seasons. Neither are out of the scope of what can be done with this ask, but I'm confident with the presented model as a first pass before adding in more complexity. I also looked into random effects on distance per player, but the spline performed slighly better and dealt with less parameters, thus less complexity. My theory is that at certain distances, players are constrained more by physics than skill, and the spline's flexibility in capturing non-linear relationships at these specific points offered a better fit than a simple random intercept/slope for each player.


## Given more time, what would your next steps be?
There are components I mentioned above, but I think theres a couple directions. Adding in tracking data could be one, but Among these, my immediate next step would be to integrate age and contract data, as these directly inform actionable insights for player valuation and contract negotiations. You can make use of the leaderboard in it's current state by manually accounting for a player's ages. If the model is showing a strong distribution, say for Adam Vinitari, leadership would know not to offer a 5-year contract, recognizing potential future decline not fully captured by current performance metrics. This kind of player analysis would be improved by projecting their value into salary cap and making projections on what value they can bring, or incorporating collegiate priors for young players to get a better grasp of their range of outcomes.

## Are there any models/techniques/areas you are unfamiliar with that might improve your work? Any new/foreign methods worth researching?
Gaussian processes are something I haven't explored much outside of academics, but they would be worth looking into. The could provide uncertainty quantification and extrapolation for player ratings, particularly valuable when projecting performance into future seasons or estimating decline curves. With tracking-data, the recent movement with transformer architectures and deep-learning is making a lot of headway reducing the amount of feature engineering needed with the use of attention. I only recently learned of Bayesian Additive Regression Trees (BART), but with the popularity of gradient boosting methods in competitions like the Big Data Bowl and large scale prediction, I would be interested in looking into that for other prediction tasks. The main theme is that if it makes sense, I would continue looking for ways to apply Bayesian methods and improve ways we can look at decision making.


## Closing Thoughts

This was an incredibly fun take-home assessment. I appreciate upfront getting to do this, and being able to have something I can take away from this. I did all of this in bambi, because the API abstracted some of the components like predicting on new data. I included a standard PYMC implementation in the github repo as well: https://github.com/rplain1/just4kicks. And if the team is R/Stan, you might tell from my `ggplot` comment, but I enjoy that as well.
