---
title: "Untitled"
format: html
---


```{python}
#import gdown
import os
from pathlib import Path
import polars as pl
from patsy import dmatrix
import pymc as pm
import numpy as np
import arviz as az
#import seaborn as sns
import pandas as pd
```


```{python}
if not Path('data').exists():
    gdown.download_folder('https://drive.google.com/drive/folders/1sDtOy_OwP7Fyy0UudUxmaZsc6fZcbCti', output = 'data')

```


```{python}
df_field_goals = pl.read_csv("data/field_goal_attempts.csv")
df_kickers = pl.read_csv("data/kickers.csv")

df = (
    df_field_goals.join(df_kickers, on="player_id")
    .rename({"attempt_yards": "distance"})
    .with_columns(
        success=pl.when(pl.col("field_goal_result") == "Made")
        .then(pl.lit(1))
        .otherwise(pl.lit(0)),
        player_id=pl.col("player_id").cast(pl.Utf8).cast(pl.Categorical),
        player_name=pl.col("player_name").cast(pl.Categorical),
        season_type=pl.col("season_type").cast(pl.Categorical),
    )
)

```

```{python}
df_plot = df.group_by('distance').agg(pl.col('success').sum() / pl.count('success'))
sns.regplot(x='distance', y='success', data=df_plot, lowess=True)  # lowess=True does a smooth locally weighted regression
```


```{python}
def categorize(col):
    return col.to_physical().cast(pl.Int64), col.cat.get_categories()
```



```{python}
# wp = idata.posterior["w"].mean(("chain", "draw")).values

# spline_df = (
#     pl.DataFrame(spline_basis * wp.T)
#     #.assign(idx=np.arange(spline_basis.shape[0]))
#    # .melt("idx", var_name="spline_i", value_name="value")
# )
```


# try random effects

```{python}

player_idx, player_cat = categorize(df["player_id"])


df = df.with_columns(
    distance_std=(pl.col("distance") - pl.col("distance").mean())
    / pl.col("distance").std()
)

spline_basis = dmatrix(
    "bs(distance_std, df=4, degree=3, include_intercept=True) - 1",
    data=df.to_pandas(),
    return_type="dataframe",
)
spline_array = np.asarray(spline_basis, order="F")
COORDS = {
    "splines": np.arange(spline_basis.shape[1]),
    "player_id": player_cat,
    "param": ["alpha", "beta"],
}

with pm.Model(coords=COORDS) as model2:

    distance_data = pm.Data("distance_data", df["distance_std"].to_numpy())
    spline_data = pm.Data("spline_data", spline_array)
    player_idx = pm.Data(
        "player_idx", df["player_id"].to_physical().cast(pl.Int64).to_numpy()
    )

    # parameters
    ### --- MODIFIED SPLINE SECTION --- ###
    # 1. Add a hyperprior for the spline penalty (this learns the smoothness)
    # This prior is similar to the brms default.
    sigma_w = pm.HalfStudentT("sigma_w", nu=3, sigma=2.5)

    # 2. Use the hyperprior in the prior for the spline weights
    w = pm.Normal("w", mu=0, sigma=sigma_w, dims="splines")
    ### --- END OF MODIFICATIONS --- ###

    sd_dist = pm.HalfNormal.dist(0.5, size=2)

    # standard deviations and rho
    chol, corr, stds = pm.LKJCholeskyCov("chol", n=2, eta=2.0, sd_dist=sd_dist)

    # intercept and slope prior
    mu_alpha_beta = pm.Normal("mu_alpha_beta", mu=0.0, sigma=0.5, shape=2)

    # population of varying effects:
    z = pm.Normal("z", 0.0, 1.0, dims=("param", "player_id"))
    alpha_beta_player = pm.Deterministic(
        "alpha_beta_player", pm.math.dot(chol, z).T, dims=("player_id", "param")
    )

    mu = (
        mu_alpha_beta[0]
        + alpha_beta_player[player_idx, 0]
        + (alpha_beta_player[player_idx, 1] * distance_data)
        + pm.math.dot(spline_data, w.T)
    )
    p = pm.Deterministic("p", pm.math.invlogit(mu))

    pm.Bernoulli("y_rep", p=p, observed=df["success"].to_numpy())
    idata = pm.sample(chains=4, cores=1, target_accept=0.95)

```



```{python}
df_2018 = (
    df.filter(pl.col("season") == 2018)
    .select(["player_id", "player_name"])
    .unique()
    .join(
        pl.DataFrame({"distance": [x for x in range(20, 61)]}).with_columns(
            distance_std=(pl.col("distance") - pl.col("distance").mean())
            / pl.col("distance").std()
        ),
        how="cross",
    )
)

df_2018


spline_basis = dmatrix(
    "bs(distance, df=4, degree=3, include_intercept=False)",
    data=df_2018.to_pandas(),
    return_type="dataframe",
).drop('Intercept', axis =1 )
spline_basis_std = (spline_basis - spline_basis.mean(axis=0)) / spline_basis.std(axis=0)
spline_array = np.asarray(spline_basis_std, order="F")

player_id_to_idx = {pid: i for i, pid in enumerate(player_cat)}

# Make sure df_2018 player_id is a string
df_2018 = df_2018.with_columns(pl.col("player_id").cast(pl.Utf8()))

# Map to player_idx using dictionary
df_2018 = df_2018.with_columns(
    pl.col("player_id")
    .cast(pl.Utf8())
    .map_elements(lambda pid: player_id_to_idx.get(pid, -1))
    .alias("player_idx")
)
# Validate no -1 values
assert (
    df_2018["player_idx"] >= 0
).all(), "Some player_ids are missing from training data!"
```


```{python}
with model2:


    df_pred = pm.sample_posterior_predictive(idata, var_names=["p", 'y_rep'], random_seed=123)

az.plot_ppc(df_pred, group='posterior', num_pp_samples=10)
```


```{python}
wp = idata.posterior["w"].mean(("chain", "draw")).values

df_spline = pd.DataFrame(spline_basis * wp.T).assign(distance=df["distance"].to_numpy()).melt("distance", var_name="spline_i", value_name="value")

df_spline.to_parquet('spline.parquet')

```


```{python}
df_output = df_2018.with_row_index("p_dim_0").join(
    pl.from_pandas(df_pred.posterior_predictive["p"].mean(dim=["chain"]).to_dataframe().reset_index()),
    on='p_dim_0'
).with_columns(
    avg_p = pl.col('p').mean().over(['distance_std', 'draw'])
).with_columns(
    fgoe = pl.col('p') - pl.col('avg_p')
)

df_output.write_parquet('df_output.parquet')
```

```{python}
df_output.group_by(['player_name']).agg(
    pl.col('fgoe').mean()
).sort('fgoe')
```



```{python}
# Make sure spline basis uses the same distance data
spline_basis = dmatrix(
    "bs(distance, df=4, degree=3, include_intercept=False)",
    data=df.to_pandas(),
    return_type="dataframe",
)


player_idx, player_cat = categorize(df["player_id"])

COORDS = {
    "splines": np.arange(spline_basis.shape[1]),
    "player_id": player_cat,
    "param": ["intercept", "slope"],  # More descriptive names
}

# Use original distance, not standardized
distance_data = df["distance"].to_numpy()

with pm.Model(coords=COORDS) as model2:

    spline_data = pm.Data("spline_data", np.asarray(spline_basis, order="F"))
    distance_data_pm = pm.Data("distance_data", distance_data)
    player_idx_pm = pm.Data("player_idx", player_idx)

    # Spline weights
    w = pm.Normal("w", mu=0, sigma=0.5, dims="splines")

    # Random effects covariance
    sd_dist = pm.HalfNormal.dist(0.5, shape=2)
    chol, corr, stds = pm.LKJCholeskyCov("chol", n=2, eta=2.0, sd_dist=sd_dist)

    # Population means for intercept and slope
    mu_intercept_slope = pm.Normal("mu_intercept_slope", mu=0.0, sigma=1.0, shape=2)

    # Random effects (intercept and slope for each player)
    z = pm.Normal("z", 0.0, 1.0, dims=("param", "player_id"))

    # Correct way to add population means to random effects
    intercept_slope_player = pm.Deterministic(
        "intercept_slope_player",
        mu_intercept_slope[None, :]
        + pm.math.dot(chol, z).T,  # Changed [:, None] to [None, :]
        dims=("player_id", "param"),
    )

    # Linear predictor
    mu = (
        intercept_slope_player[player_idx_pm, 0]  # Random intercept
        + intercept_slope_player[player_idx_pm, 1] * distance_data_pm  # Random slope
        + pm.math.dot(spline_data, w)  # Spline component
    )

    p = pm.Deterministic("p", pm.math.invlogit(mu))
    pm.Bernoulli("y_rep", p=p, observed=df["success"].to_numpy())

    idata = pm.sample(cores=1, chains=4)
```
